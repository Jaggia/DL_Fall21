{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', lower = True)\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = data.TabularDataset(\n",
    "    path='input/News_Category_Dataset_v2.json', format='json',\n",
    "    fields={'headline': ('headline', TEXT),\n",
    "            'short_description' : ('desc', TEXT),\n",
    "             'category': ('category', LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 1234\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "trn, vld, tst = news.split(split_ratio=[0.7, 0.2, 0.1], random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'headline': [\"'\", 'train', 'hard', ',', 'land', 'soft', \"'\"],\n 'desc': ['runners',\n  'will',\n  'appreciate',\n  'that',\n  'the',\n  'sproing',\n  'trainer',\n  'was',\n  'designed',\n  'with',\n  'them',\n  'in',\n  'mind',\n  'as',\n  'a',\n  'way',\n  'to',\n  'build',\n  'endurance',\n  'and',\n  'strength',\n  'without',\n  'the',\n  'pain',\n  'that',\n  'can',\n  'come',\n  'with',\n  'pounding',\n  'the',\n  'pavement',\n  '.'],\n 'category': 'HEALTHY LIVING'}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78590\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab))\n",
    "print(len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'POLITICS': 0, 'WELLNESS': 1, 'ENTERTAINMENT': 2, 'TRAVEL': 3, 'STYLE & BEAUTY': 4, 'PARENTING': 5, 'HEALTHY LIVING': 6, 'QUEER VOICES': 7, 'FOOD & DRINK': 8, 'BUSINESS': 9, 'COMEDY': 10, 'SPORTS': 11, 'BLACK VOICES': 12, 'HOME & LIVING': 13, 'PARENTS': 14, 'THE WORLDPOST': 15, 'WEDDINGS': 16, 'DIVORCE': 17, 'WOMEN': 18, 'IMPACT': 19, 'CRIME': 20, 'MEDIA': 21, 'WEIRD NEWS': 22, 'GREEN': 23, 'WORLDPOST': 24, 'RELIGION': 25, 'STYLE': 26, 'SCIENCE': 27, 'TASTE': 28, 'WORLD NEWS': 29, 'TECH': 30, 'MONEY': 31, 'ARTS': 32, 'FIFTY': 33, 'GOOD NEWS': 34, 'ARTS & CULTURE': 35, 'ENVIRONMENT': 36, 'COLLEGE': 37, 'LATINO VOICES': 38, 'CULTURE & ARTS': 39, 'EDUCATION': 40})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (trn, vld, tst), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key= lambda x: len(x.headline), \n",
    "    sort_within_batch= False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
    "        \n",
    "        self.lstm_head = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout).to(device)\n",
    "        \n",
    "        self.lstm_desc = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout).to(device)\n",
    "        \n",
    "        self.fc_head = nn.Linear(hidden_dim * 2, 100).to(device)\n",
    "        \n",
    "        self.fc_desc = nn.Linear(hidden_dim * 2, 100).to(device)\n",
    "\n",
    "        self.fc_total = nn.Linear(200, output_dim).to(device)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "                \n",
    "    def forward(self, headline, description):\n",
    "                        \n",
    "        embedded_head = self.dropout(self.embedding(headline))\n",
    "        \n",
    "        embedded_desc = self.dropout(self.embedding(description))\n",
    "                                    \n",
    "        output_head, (hidden_head, cell_head) = self.lstm_head(embedded_head)\n",
    "        \n",
    "        output_desc, (hidden_desc, cell_desc) = self.lstm_desc(embedded_desc)\n",
    "        \n",
    "        hidden_head = self.dropout(torch.cat((hidden_head[-2, :, :], hidden_head[-1, :, :]), dim = 1))\n",
    "        \n",
    "        hidden_desc = self.dropout(torch.cat((hidden_desc[-2, :, :], hidden_desc[-1, :, :]), dim = 1))\n",
    "        \n",
    "        full_head = self.fc_head(hidden_head)\n",
    "        \n",
    "        full_desc = self.fc_desc(hidden_desc)\n",
    "        \n",
    "        hidden_total = torch.cat((full_head, full_desc), 1)\n",
    "        \n",
    "        return self.fc_total(hidden_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,590,129 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78590, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.3163, -1.0334,  1.3341,  ..., -0.9349, -0.9871,  0.8570],\n        [-0.2177,  1.2816, -1.8185,  ...,  1.5708, -1.3168,  1.2243],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [ 0.2739,  1.5988,  1.6253,  ..., -0.7998,  0.9562, -0.3763],\n        [ 1.1755,  1.3740, -0.0853,  ..., -0.0369,  0.7275, -1.8354],\n        [-0.4112,  0.5026,  0.7018,  ..., -0.8129, -0.8108, -0.4398]],\n       device='cuda:0')"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.DiceLoss import DiceLoss\n",
    "criterion = DiceLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True).to(device)\n",
    "    correct = max_preds.squeeze(1).eq(y).to(device)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, f1, precision\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # Get the progress bar for later modification\n",
    "    # progress_bar = tqdm_notebook(iterator, ascii=True)\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                        \n",
    "        predictions = model(batch.headline, batch.desc)\n",
    "#         print(predictions.shape)\n",
    "        predictions = predictions.squeeze(1)\n",
    "#         print(batch.category)\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        my_acc = accuracy(predictions, batch.category)\n",
    "        my_f1 = f1(predictions, batch.category, num_classes=41)\n",
    "        my_prec = precision(predictions, batch.category, average='micro')\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        # progress_bar.set_description_str(\n",
    "        #     \"Batch: %d, Loss: %.4f\" % (int(idx + 1), loss.item()))\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), my_acc, my_f1, my_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch.headline, batch.desc).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "            my_acc = accuracy(predictions, batch.category)\n",
    "            my_f1 = f1(predictions, batch.category, num_classes=41)\n",
    "            my_prec = precision(predictions, batch.category, average='micro')\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), my_acc, my_f1, my_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from losses.LDAMLoss import LDAMLoss\n",
    "import torch.optim as optim\n",
    "lr = 0.0003\n",
    "betas = [0.9, 0.99999]\n",
    "weight_decay = 0.0000\n",
    "# lr = 0.001\n",
    "# momentum = 0.9\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)  #, betas=betas)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "#                             momentum=momentum,\n",
    "#                             weight_decay=weight_decay)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "#                                                        patience=0, threshold=.5,\n",
    "#                                                        cooldown=0, factor=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2, last_epoch=-1)\n",
    "# lr_idx = [0.0005, 0.0005, 0.0001, 0.0001]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anadi\\anaconda3\\envs\\OMSCS\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 18s\n",
      "\t Train Loss: 0.873 | Train Acc: 33.27 | My Train Acc: 34.38%\n",
      "\t Train F1: 34.38 | My Train Precision: 34.38%\n",
      "\t Val. Loss: 0.845 |  Val. Acc: 33.68 | My Val Acc: 37.74%\n",
      "\t Valid F1: 37.74 | My Val Precision: 37.74%\n",
      "\t LR: 0.0001797656\n",
      "Epoch: 02 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.793 | Train Acc: 43.34 | My Train Acc: 37.50%\n",
      "\t Train F1: 37.50 | My Train Precision: 37.50%\n",
      "\t Val. Loss: 0.786 |  Val. Acc: 43.69 | My Val Acc: 35.85%\n",
      "\t Valid F1: 35.85 | My Val Precision: 35.85%\n",
      "\t LR: 0.0001980173\n",
      "Epoch: 03 | Epoch Time: 1m 15s\n",
      "\t Train Loss: 0.762 | Train Acc: 47.57 | My Train Acc: 46.88%\n",
      "\t Train F1: 46.88 | My Train Precision: 46.88%\n",
      "\t Val. Loss: 0.766 |  Val. Acc: 48.59 | My Val Acc: 43.40%\n",
      "\t Valid F1: 43.40 | My Val Precision: 43.40%\n",
      "\t LR: 0.0002048570\n",
      "Epoch: 04 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.738 | Train Acc: 50.96 | My Train Acc: 56.25%\n",
      "\t Train F1: 56.25 | My Train Precision: 56.25%\n",
      "\t Val. Loss: 0.752 |  Val. Acc: 50.05 | My Val Acc: 45.28%\n",
      "\t Valid F1: 45.28 | My Val Precision: 45.28%\n",
      "\t LR: 0.0002099263\n",
      "Epoch: 05 | Epoch Time: 1m 15s\n",
      "\t Train Loss: 0.720 | Train Acc: 53.23 | My Train Acc: 57.81%\n",
      "\t Train F1: 57.81 | My Train Precision: 57.81%\n",
      "\t Val. Loss: 0.737 |  Val. Acc: 50.99 | My Val Acc: 47.17%\n",
      "\t Valid F1: 47.17 | My Val Precision: 47.17%\n",
      "\t LR: 0.0002139343\n",
      "Epoch: 06 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.706 | Train Acc: 54.71 | My Train Acc: 62.50%\n",
      "\t Train F1: 62.50 | My Train Precision: 62.50%\n",
      "\t Val. Loss: 0.725 |  Val. Acc: 54.23 | My Val Acc: 58.49%\n",
      "\t Valid F1: 58.49 | My Val Precision: 58.49%\n",
      "\t LR: 0.0002168868\n",
      "Epoch: 07 | Epoch Time: 1m 16s\n",
      "\t Train Loss: 0.693 | Train Acc: 56.48 | My Train Acc: 60.94%\n",
      "\t Train F1: 60.94 | My Train Precision: 60.94%\n",
      "\t Val. Loss: 0.722 |  Val. Acc: 54.62 | My Val Acc: 54.72%\n",
      "\t Valid F1: 54.72 | My Val Precision: 54.72%\n",
      "\t LR: 0.0002195535\n",
      "Epoch: 08 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 0.682 | Train Acc: 57.74 | My Train Acc: 60.94%\n",
      "\t Train F1: 60.94 | My Train Precision: 60.94%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 55.71 | My Val Acc: 64.15%\n",
      "\t Valid F1: 64.15 | My Val Precision: 64.15%\n",
      "\t LR: 0.0002217737\n",
      "Epoch: 09 | Epoch Time: 1m 14s\n",
      "\t Train Loss: 0.673 | Train Acc: 58.84 | My Train Acc: 54.69%\n",
      "\t Train F1: 54.69 | My Train Precision: 54.69%\n",
      "\t Val. Loss: 0.708 |  Val. Acc: 55.45 | My Val Acc: 64.15%\n",
      "\t Valid F1: 64.15 | My Val Precision: 64.15%\n",
      "\t LR: 0.0002237119\n",
      "Epoch: 10 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 0.664 | Train Acc: 60.10 | My Train Acc: 60.94%\n",
      "\t Train F1: 60.94 | My Train Precision: 60.94%\n",
      "\t Val. Loss: 0.704 |  Val. Acc: 56.63 | My Val Acc: 62.26%\n",
      "\t Valid F1: 62.26 | My Val Precision: 62.26%\n",
      "\t LR: 0.0002254788\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, my_train_acc, my_train_f1, my_train_prec = train(model, train_iterator, optimizer, criterion)\n",
    "    scheduler.step(train_loss)\n",
    "    valid_loss, valid_acc, my_valid_acc, my_valid_f1, my_valid_prec = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'news_classification_model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | My Train Acc: {my_train_acc*100:.2f}%')\n",
    "    print(f'\\t Train F1: {my_train_f1*100:.2f} | My Train Precision: {my_train_prec*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | My Val Acc: {my_valid_acc*100:.2f}%')\n",
    "    print(f'\\t Valid F1: {my_valid_f1*100:.2f} | My Val Precision: {my_valid_prec*100:.2f}%')\n",
    "    llrr = optimizer.param_groups[0]['lr']\n",
    "    print(f'\\t LR: {llrr:.10f}')\n",
    "    # optimizer.param_groups[0]['lr'] = lr_idx[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.706 | Test Acc: 57.06 | My Test Acc: 48.84 | Test F1: 48.84 | Test Prec: 48.84%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, my_test_acc, my_test_f1, my_test_prec = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} '\n",
    "      f'| Test Acc: {test_acc*100:.2f} | My Test Acc: {my_test_acc*100:.2f} '\n",
    "      f'| Test F1: {my_test_f1*100:.2f} | Test Prec: {my_test_prec*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_category(model, head, desc):\n",
    "    model.eval()\n",
    "    head = head.lower()\n",
    "    desc = desc.lower()\n",
    "    tokenized_head = [tok.text for tok in nlp.tokenizer(head)]\n",
    "    tokenized_desc = [tok.text for tok in nlp.tokenizer(desc)]\n",
    "    indexed_head = [TEXT.vocab.stoi[t] for t in tokenized_head]\n",
    "    indexed_desc = [TEXT.vocab.stoi[t] for t in tokenized_desc]\n",
    "    tensor_head = torch.LongTensor(indexed_head).to(device)\n",
    "    tensor_desc = torch.LongTensor(indexed_desc).to(device)\n",
    "    tensor_head = tensor_head.unsqueeze(1)\n",
    "    tensor_desc = tensor_desc.unsqueeze(1)\n",
    "    prediction = model(tensor_head, tensor_desc)\n",
    "    max_pred = prediction.argmax(dim=1)\n",
    "    return max_pred.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News headline: Trump’s Art Of Distraction\n",
    "\n",
    "News short description: The conversation surrounding Trump’s latest racist rants has provoked us to revisit author Toni Morrison’s 1975 keynote address at Portland State University on the true purpose of racism.\n",
    "\n",
    "Correct category: Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 40 = EDUCATION\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Trump’s Art Of Distraction\", \"The conversation surrounding Trump’s latest racist rants has provoked us to revisit author Toni Morrison’s 1975 keynote address at Portland State University on the true purpose of racism..\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News headline: Indiana Cop Apologizes After Accusing McDonald’s Worker Of Eating His Sandwich\n",
    "\n",
    "News short description: The Marion County sheriff’s deputy forgot he had taken a bite out of his McChicken earlier that day, authorities said.\n",
    "\n",
    "Correct category: U.S. News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 20 = CRIME\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Indiana Cop Apologizes After Accusing McDonald’s Worker Of Eating His Sandwich\", \"The Marion County sheriff’s deputy forgot he had taken a bite out of his McChicken earlier that day, authorities said.\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News headline: Kyle ‘Bugha’ Giersdorf, 16, Wins Fortnite World Cup And Takes Home $ 3 Million Prize\n",
    "\n",
    "News short description: Fortnite has nearly 250 million registered players and raked in an estimated $2.4 billion last year.\n",
    "\n",
    "Correct category: Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 8 = FOOD & DRINK\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Kyle ‘Bugha’ Giersdorf, 16, Wins Fortnite World Cup And Takes Home $ 3 Million Prize\", \"Fortnite has nearly 250 million registered players and raked in an estimated $2.4 billion last year.\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "This notebook was created thanks to the two references below.\n",
    "* http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "* https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}