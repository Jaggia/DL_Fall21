{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy', lower = True)\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = data.TabularDataset(\n",
    "    path='input/News_Category_Dataset_v2.json', format='json',\n",
    "    fields={'headline': ('headline', TEXT),\n",
    "            'short_description' : ('desc', TEXT),\n",
    "             'category': ('category', LABEL)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "SEED = 1234\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "trn, vld, tst = news.split(split_ratio=[0.7, 0.2, 0.1], random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'headline': [\"'\", 'train', 'hard', ',', 'land', 'soft', \"'\"],\n 'desc': ['runners',\n  'will',\n  'appreciate',\n  'that',\n  'the',\n  'sproing',\n  'trainer',\n  'was',\n  'designed',\n  'with',\n  'them',\n  'in',\n  'mind',\n  'as',\n  'a',\n  'way',\n  'to',\n  'build',\n  'endurance',\n  'and',\n  'strength',\n  'without',\n  'the',\n  'pain',\n  'that',\n  'can',\n  'come',\n  'with',\n  'pounding',\n  'the',\n  'pavement',\n  '.'],\n 'category': 'HEALTHY LIVING'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trn, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78590\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "print(len(TEXT.vocab))\n",
    "print(len(LABEL.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'POLITICS': 0, 'WELLNESS': 1, 'ENTERTAINMENT': 2, 'TRAVEL': 3, 'STYLE & BEAUTY': 4, 'PARENTING': 5, 'HEALTHY LIVING': 6, 'QUEER VOICES': 7, 'FOOD & DRINK': 8, 'BUSINESS': 9, 'COMEDY': 10, 'SPORTS': 11, 'BLACK VOICES': 12, 'HOME & LIVING': 13, 'PARENTS': 14, 'THE WORLDPOST': 15, 'WEDDINGS': 16, 'DIVORCE': 17, 'WOMEN': 18, 'IMPACT': 19, 'CRIME': 20, 'MEDIA': 21, 'WEIRD NEWS': 22, 'GREEN': 23, 'WORLDPOST': 24, 'RELIGION': 25, 'STYLE': 26, 'SCIENCE': 27, 'TASTE': 28, 'WORLD NEWS': 29, 'TECH': 30, 'MONEY': 31, 'ARTS': 32, 'FIFTY': 33, 'GOOD NEWS': 34, 'ARTS & CULTURE': 35, 'ENVIRONMENT': 36, 'COLLEGE': 37, 'LATINO VOICES': 38, 'CULTURE & ARTS': 39, 'EDUCATION': 40})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (trn, vld, tst), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key= lambda x: len(x.headline), \n",
    "    sort_within_batch= False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "                \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
    "        \n",
    "        self.lstm_head = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout).to(device)\n",
    "        \n",
    "        self.lstm_desc = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout).to(device)\n",
    "        \n",
    "        self.fc_head = nn.Linear(hidden_dim * 2, 100).to(device)\n",
    "        \n",
    "        self.fc_desc = nn.Linear(hidden_dim * 2, 100).to(device)\n",
    "\n",
    "        self.fc_total = nn.Linear(200, output_dim).to(device)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout).to(device)\n",
    "                \n",
    "    def forward(self, headline, description):\n",
    "                        \n",
    "        embedded_head = self.dropout(self.embedding(headline))\n",
    "        \n",
    "        embedded_desc = self.dropout(self.embedding(description))\n",
    "                                    \n",
    "        output_head, (hidden_head, cell_head) = self.lstm_head(embedded_head)\n",
    "        \n",
    "        output_desc, (hidden_desc, cell_desc) = self.lstm_desc(embedded_desc)\n",
    "        \n",
    "        hidden_head = self.dropout(torch.cat((hidden_head[-2, :, :], hidden_head[-1, :, :]), dim = 1))\n",
    "        \n",
    "        hidden_desc = self.dropout(torch.cat((hidden_desc[-2, :, :], hidden_desc[-1, :, :]), dim = 1))\n",
    "        \n",
    "        full_head = self.fc_head(hidden_head)\n",
    "        \n",
    "        full_desc = self.fc_desc(hidden_desc)\n",
    "        \n",
    "        hidden_total = torch.cat((full_head, full_desc), 1)\n",
    "        \n",
    "        return self.fc_total(hidden_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 12,590,129 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78590, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.7434,  0.5968,  1.1194,  ..., -0.8323,  0.2238,  1.1770],\n        [-1.1985, -0.1760, -0.9794,  ..., -0.5715,  1.4031, -0.5824],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [ 1.0710,  0.6113,  0.3432,  ..., -1.4114,  0.9248, -1.0107],\n        [-1.3634,  0.6553,  0.1724,  ...,  1.5458, -0.4808,  0.8539],\n        [-1.0424, -1.4641,  0.7621,  ..., -1.0989,  0.6634,  1.6377]],\n       device='cuda:0')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True).to(device)\n",
    "    correct = max_preds.squeeze(1).eq(y).to(device)\n",
    "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import accuracy, f1, precision\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # Get the progress bar for later modification\n",
    "    # progress_bar = tqdm_notebook(iterator, ascii=True)\n",
    "    for idx, batch in enumerate(iterator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                        \n",
    "        predictions = model(batch.headline, batch.desc)\n",
    "#         print(predictions.shape)\n",
    "        predictions = predictions.squeeze(1)\n",
    "#         print(batch.category)\n",
    "        \n",
    "        loss = criterion(predictions, batch.category)\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.category)\n",
    "        my_acc = accuracy(predictions, batch.category)\n",
    "        my_f1 = f1(predictions, batch.category, num_classes=41)\n",
    "        my_prec = precision(predictions, batch.category, average='micro')\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "        # progress_bar.set_description_str(\n",
    "        #     \"Batch: %d, Loss: %.4f\" % (int(idx + 1), loss.item()))\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), my_acc, my_f1, my_prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            \n",
    "            predictions = model(batch.headline, batch.desc).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.category)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.category)\n",
    "            my_acc = accuracy(predictions, batch.category)\n",
    "            my_f1 = f1(predictions, batch.category, num_classes=41)\n",
    "            my_prec = precision(predictions, batch.category, average='micro')\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), my_acc, my_f1, my_prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cls_num_list = []\n",
    "cat_map = dict()\n",
    "for r in news:\n",
    "    cat = r.category\n",
    "    if cat not in cat_map:\n",
    "        cat_map[cat] = 0\n",
    "    else:\n",
    "        cat_map[cat] += 1\n",
    "for v in cat_map.values():\n",
    "    cls_num_list.append(v)\n",
    "cls_num_list = sorted(cls_num_list, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses.LDAMLoss import LDAMLoss\n",
    "import torch.optim as optim\n",
    "lr = 0.0002\n",
    "betas = [0.9, 0.99999]\n",
    "weight_decay = 0.00001\n",
    "# lr = 0.001\n",
    "# momentum = 0.9\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)  #, betas=betas)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr,\n",
    "#                             momentum=momentum,\n",
    "#                             weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       patience=1, threshold=.5,\n",
    "                                                       cooldown=0, factor=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, last_epoch=-1)\n",
    "# lr_idx = [0.0005, 0.0005, 0.0001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anadi\\Desktop\\OMSCS\\CS_7643\\Assignments_7643\\Project\\DL_Fall21\\DL_Fall21\\losses\\LDAMLoss.py:49: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:328.)\n",
      "  output = torch.where(index, x_m, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 18s\n",
      "\t Train Loss: 3.064 | Train Acc: 48.79 | My Train Acc: 59.38%\n",
      "\t Train F1: 59.38 | My Train Precision: 59.38%\n",
      "\t Val. Loss: 2.571 |  Val. Acc: 57.24 | My Val Acc: 62.26%\n",
      "\t Valid F1: 62.26 | My Val Precision: 62.26%\n",
      "\t LR: 0.0002000000\n",
      "Epoch: 02 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 2.441 | Train Acc: 59.45 | My Train Acc: 62.50%\n",
      "\t Train F1: 62.50 | My Train Precision: 62.50%\n",
      "\t Val. Loss: 2.335 |  Val. Acc: 61.33 | My Val Acc: 67.92%\n",
      "\t Valid F1: 67.92 | My Val Precision: 67.92%\n",
      "\t LR: 0.0002000000\n",
      "Epoch: 03 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 2.199 | Train Acc: 63.50 | My Train Acc: 62.50%\n",
      "\t Train F1: 62.50 | My Train Precision: 62.50%\n",
      "\t Val. Loss: 2.202 |  Val. Acc: 63.66 | My Val Acc: 69.81%\n",
      "\t Valid F1: 69.81 | My Val Precision: 69.81%\n",
      "\t LR: 0.0000200000\n",
      "Epoch: 04 | Epoch Time: 1m 14s\n",
      "\t Train Loss: 1.967 | Train Acc: 67.43 | My Train Acc: 67.19%\n",
      "\t Train F1: 67.19 | My Train Precision: 67.19%\n",
      "\t Val. Loss: 2.117 |  Val. Acc: 65.24 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000200000\n",
      "Epoch: 05 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 1.931 | Train Acc: 68.07 | My Train Acc: 70.31%\n",
      "\t Train F1: 70.31 | My Train Precision: 70.31%\n",
      "\t Val. Loss: 2.112 |  Val. Acc: 65.29 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000020000\n",
      "Epoch: 06 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 9.356 | Train Acc: 65.53 | My Train Acc: 59.38%\n",
      "\t Train F1: 59.38 | My Train Precision: 59.38%\n",
      "\t Val. Loss: 10.146 |  Val. Acc: 63.21 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000020000\n",
      "Epoch: 07 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 9.223 | Train Acc: 65.18 | My Train Acc: 59.38%\n",
      "\t Train F1: 59.38 | My Train Precision: 59.38%\n",
      "\t Val. Loss: 10.097 |  Val. Acc: 63.37 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000002000\n",
      "Epoch: 08 | Epoch Time: 1m 13s\n",
      "\t Train Loss: 9.181 | Train Acc: 65.52 | My Train Acc: 73.44%\n",
      "\t Train F1: 73.44 | My Train Precision: 73.44%\n",
      "\t Val. Loss: 10.090 |  Val. Acc: 63.36 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000002000\n",
      "Epoch: 09 | Epoch Time: 1m 14s\n",
      "\t Train Loss: 9.187 | Train Acc: 65.34 | My Train Acc: 56.25%\n",
      "\t Train F1: 56.25 | My Train Precision: 56.25%\n",
      "\t Val. Loss: 10.086 |  Val. Acc: 63.30 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000000200\n",
      "Epoch: 10 | Epoch Time: 1m 15s\n",
      "\t Train Loss: 9.169 | Train Acc: 65.40 | My Train Acc: 54.69%\n",
      "\t Train F1: 54.69 | My Train Precision: 54.69%\n",
      "\t Val. Loss: 10.086 |  Val. Acc: 63.29 | My Val Acc: 71.70%\n",
      "\t Valid F1: 71.70 | My Val Precision: 71.70%\n",
      "\t LR: 0.0000000200\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    if epoch+1 <= 5:\n",
    "        idx = 0\n",
    "        maxm = 0.25\n",
    "        s = 10\n",
    "    else:\n",
    "        idx = 1\n",
    "        maxm = 0.5\n",
    "        s = 30\n",
    "\n",
    "    betas = [0, 0.9999]\n",
    "    effective_num = 1.0 - np.power(betas[idx], cls_num_list)\n",
    "    per_cls_weights = (1.0 - betas[idx]) / np.array(effective_num)\n",
    "    per_cls_weights = per_cls_weights / np.sum(per_cls_weights) * len(cls_num_list)\n",
    "    per_cls_weights = torch.FloatTensor(per_cls_weights).to(device)\n",
    "    # per_cls_weights = per_cls_weights.detach().numpy()\n",
    "    criterion = LDAMLoss(cls_num_list=cls_num_list, weight=per_cls_weights, max_m=maxm, s=s)\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, my_train_acc, my_train_f1, my_train_prec = train(model, train_iterator, optimizer, criterion)\n",
    "    scheduler.step(train_loss)\n",
    "    valid_loss, valid_acc, my_valid_acc, my_valid_f1, my_valid_prec = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'news_classification_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\t Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | My Train Acc: {my_train_acc*100:.2f}%')\n",
    "    print(f'\\t Train F1: {my_train_f1*100:.2f} | My Train Precision: {my_train_prec*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | My Val Acc: {my_valid_acc*100:.2f}%')\n",
    "    print(f'\\t Valid F1: {my_valid_f1*100:.2f} | My Val Precision: {my_valid_prec*100:.2f}%')\n",
    "    llrr = optimizer.param_groups[0]['lr']\n",
    "    print(f'\\t LR: {llrr:.10f}')\n",
    "    # optimizer.param_groups[0]['lr'] = lr_idx[epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 10.146 | Test Acc: 63.18 | My Test Acc: 60.47 | Test F1: 60.47 | Test Prec: 60.47%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, my_test_acc, my_test_f1, my_test_prec = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} '\n",
    "      f'| Test Acc: {test_acc*100:.2f} | My Test Acc: {my_test_acc*100:.2f} '\n",
    "      f'| Test F1: {my_test_f1*100:.2f} | Test Prec: {my_test_prec*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_category(model, head, desc):\n",
    "    model.eval()\n",
    "    head = head.lower()\n",
    "    desc = desc.lower()\n",
    "    tokenized_head = [tok.text for tok in nlp.tokenizer(head)]\n",
    "    tokenized_desc = [tok.text for tok in nlp.tokenizer(desc)]\n",
    "    indexed_head = [TEXT.vocab.stoi[t] for t in tokenized_head]\n",
    "    indexed_desc = [TEXT.vocab.stoi[t] for t in tokenized_desc]\n",
    "    tensor_head = torch.LongTensor(indexed_head).to(device)\n",
    "    tensor_desc = torch.LongTensor(indexed_desc).to(device)\n",
    "    tensor_head = tensor_head.unsqueeze(1)\n",
    "    tensor_desc = tensor_desc.unsqueeze(1)\n",
    "    prediction = model(tensor_head, tensor_desc)\n",
    "    max_pred = prediction.argmax(dim=1)\n",
    "    return max_pred.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "News headline: Trump’s Art Of Distraction\n",
    "\n",
    "News short description: The conversation surrounding Trump’s latest racist rants has provoked us to revisit author Toni Morrison’s 1975 keynote address at Portland State University on the true purpose of racism.\n",
    "\n",
    "Correct category: Politics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 0 = POLITICS\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Trump’s Art Of Distraction\", \"The conversation surrounding Trump’s latest racist rants has provoked us to revisit author Toni Morrison’s 1975 keynote address at Portland State University on the true purpose of racism..\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News headline: Indiana Cop Apologizes After Accusing McDonald’s Worker Of Eating His Sandwich\n",
    "\n",
    "News short description: The Marion County sheriff’s deputy forgot he had taken a bite out of his McChicken earlier that day, authorities said.\n",
    "\n",
    "Correct category: U.S. News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 20 = CRIME\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Indiana Cop Apologizes After Accusing McDonald’s Worker Of Eating His Sandwich\", \"The Marion County sheriff’s deputy forgot he had taken a bite out of his McChicken earlier that day, authorities said.\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "News headline: Kyle ‘Bugha’ Giersdorf, 16, Wins Fortnite World Cup And Takes Home $ 3 Million Prize\n",
    "\n",
    "News short description: Fortnite has nearly 250 million registered players and raked in an estimated $2.4 billion last year.\n",
    "\n",
    "Correct category: Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted category is: 19 = IMPACT\n"
     ]
    }
   ],
   "source": [
    "pred = predict_category(model, \"Kyle ‘Bugha’ Giersdorf, 16, Wins Fortnite World Cup And Takes Home $ 3 Million Prize\", \"Fortnite has nearly 250 million registered players and raked in an estimated $2.4 billion last year.\")\n",
    "print(f'Predicted category is: {pred} = {LABEL.vocab.itos[pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "This notebook was created thanks to the two references below.\n",
    "* http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
    "* https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/2%20-%20Upgraded%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}