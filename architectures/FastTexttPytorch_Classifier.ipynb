{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlineDesc</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 5...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        headlineDesc       category\n",
       "0  There Were 2 Mass Shootings In Texas Last Week...          CRIME\n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...  ENTERTAINMENT\n",
       "2  Hugh Grant Marries For The First Time At Age 5...  ENTERTAINMENT\n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...  ENTERTAINMENT\n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...  ENTERTAINMENT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(file_path):\n",
    "    df = pd.read_json(file_path, lines = True)\n",
    "    df['category'] = pd.Categorical(df['category'])\n",
    "    df = df[df[\"short_description\"] != \"\"]\n",
    "    df['headlineDesc'] = df['headline']+ ' ' + df['short_description']\n",
    "    return df[[\"headlineDesc\", \"category\"]]\n",
    "\n",
    "df = load_data('Data/News_Category_Dataset_v2.json')\n",
    "df_orig = df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362282\n",
      "             category                                       headlineDesc\n",
      "68091           TASTE  This PB&J Bourbon Comes With A Side Of Childho...\n",
      "4800         POLITICS  Rebuffing Yet Another Trump Attack, Sessions P...\n",
      "186304      PARENTING  Spanking Alternatives: Experts' 8 Top Tips For...\n",
      "30729           CRIME  Police Thwart Plot To Steal Enzo Ferrari’s Rem...\n",
      "98021   ENTERTAINMENT  Humphrey Bogart and Clint Eastwood Still Make ...\n",
      "        category                                       headlineDesc\n",
      "0          TASTE  This PB&J Bourbon Comes With A Side Of Childho...\n",
      "1       POLITICS  Rebuffing Yet Another Trump Attack, Sessions P...\n",
      "2      PARENTING  Spanking Alternatives: Experts' 8 Top Tips For...\n",
      "3          CRIME  Police Thwart Plot To Steal Enzo Ferrari’s Rem...\n",
      "4  ENTERTAINMENT  Humphrey Bogart and Clint Eastwood Still Make ...\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "df = df_orig\n",
    "column_names = [\"category\", \"headlineDesc\"]\n",
    "df = df.reindex(columns=column_names)\n",
    "num_records = df.size\n",
    "print(num_records)\n",
    "def shuffle_data(data):\n",
    "    data = shuffle(data)\n",
    "    print(data.head())\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    return data\n",
    "    \n",
    "def fasttext_format(df_basic, per_train=0.7):\n",
    "    def take_percent_rows(data, perc=0.7, headortail=\"head\"):\n",
    "        if(headortail==\"head\"):\n",
    "            return data.head(int(len(data)*(perc)))\n",
    "        else:\n",
    "            return data.tail(int(len(data)*(perc)))\n",
    "    def format_text(data):\n",
    "        data['category_formatted'] ='__label__' + data['category'].astype(str)\n",
    "        return data[['category_formatted', 'headlineDesc']]\n",
    "        \n",
    "    df_train = take_percent_rows(df_basic, perc=per_train, headortail=\"head\")\n",
    "    df_valid = take_percent_rows(df_basic, perc=(1-per_train), headortail=\"tail\")\n",
    "    \n",
    "    df_train = format_text(df_train)\n",
    "    df_valid = format_text(df_valid)\n",
    "    \n",
    "    return df_train, df_valid\n",
    "\n",
    "df = shuffle_data(df)\n",
    "print(df.head())\n",
    "# df_train, df_valid = fasttext_format(df)\n",
    "\n",
    "# print(len(df_train.index))\n",
    "# print(len(df_valid.index))\n",
    "\n",
    "# df_train.to_csv('Data/news_titles.train', header=None, index=None, sep='\\t')\n",
    "# df_valid.to_csv('Data/news_titles.valid', header=None, index=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "text_field = Field(\n",
    "    tokenize='basic_english', \n",
    "    lower=True\n",
    ")\n",
    "label_field = Field(sequential=False, use_vocab=False)\n",
    "# sadly have to apply preprocess manually\n",
    "preprocessed_text = df['headlineDesc'].apply(lambda x: text_field.preprocess(x))\n",
    "# load fastext simple embedding with 300d\n",
    "text_field.build_vocab(\n",
    "    preprocessed_text, \n",
    "    vectors='fasttext.simple.300d'\n",
    ")\n",
    "# get the vocab instance\n",
    "vocab = text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fasttext Embeddings\n",
    "from torchtext.vocab import FastText\n",
    "embedding = FastText('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1086\n"
     ]
    }
   ],
   "source": [
    "# known token, in my case print 12\n",
    "print(vocab['are'])\n",
    "# unknown token, will print 0\n",
    "print(vocab['crazy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8806,  0.6474, -0.2148, -0.8530,  0.5135]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "####### FOLLOWING CELLS INSPIRED BY PYTORCH OFFICIAL TURORIALS #######\n",
    "####### https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html ######\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114813\n",
      "tensor([[ 0.8517,  1.3011,  0.5214,  0.8494, -0.5577]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = vocab\n",
    "print(len(vocab))\n",
    "embeds = nn.Embedding(114813, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([vocab['the']], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Requested tokenizer <torchtext.vocab.FastText object at 0x000001BFB16C2070>, valid choices are a callable that takes a single string as input, \"revtok\" for the revtok reversible tokenizer, \"subword\" for the revtok caps-aware tokenizer, \"spacy\" for the SpaCy English tokenizer, or \"moses\" for the NLTK port of the Moses tokenization script.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3692/2360268436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'simple'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\deeplearn\\lib\\site-packages\\torchtext\\data\\utils.py\u001b[0m in \u001b[0;36mget_tokenizer\u001b[1;34m(tokenizer, language)\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please install revtok.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     raise ValueError(\"Requested tokenizer {}, valid choices are a \"\n\u001b[0m\u001b[0;32m    160\u001b[0m                      \u001b[1;34m\"callable that takes a single string as input, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                      \u001b[1;34m\"\\\"revtok\\\" for the revtok reversible tokenizer, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Requested tokenizer <torchtext.vocab.FastText object at 0x000001BFB16C2070>, valid choices are a callable that takes a single string as input, \"revtok\" for the revtok reversible tokenizer, \"subword\" for the revtok caps-aware tokenizer, \"spacy\" for the SpaCy English tokenizer, or \"moses\" for the NLTK port of the Moses tokenization script."
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch\n",
    "from torchtext.legacy import data\n",
    "\n",
    "# TEXT = data.Field(tokenize = 'spacy', lower = True)\n",
    "# LABEL = data.LabelField()\n",
    "TEXT = text_field\n",
    "LABEL = label_field\n",
    "\n",
    "news = data.TabularDataset(\n",
    "    path='input/News_Category_Dataset_v2.json', format='json',\n",
    "    fields={'headline': ('headline', TEXT),\n",
    "            'short_description' : ('desc', TEXT),\n",
    "             'category': ('category', LABEL)})\n",
    "\n",
    "import random\n",
    "SEED = 1234\n",
    "\n",
    "trn, vld, tst = news.split(split_ratio=[0.7, 0.2, 0.1], random_state = random.seed(SEED))\n",
    "\n",
    "TEXT.build_vocab(trn, \n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (trn, vld, tst), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key= lambda x: len(x.headline), \n",
    "    sort_within_batch= False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = ModelParam(\n",
    "    param_dict=dict(\n",
    "        vocab_size=len(text_field.vocab),\n",
    "        input_size=5\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}